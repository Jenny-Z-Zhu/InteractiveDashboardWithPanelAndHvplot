importScripts("https://cdn.jsdelivr.net/pyodide/v0.27.2/full/pyodide.js");

function sendPatch(patch, buffers, msg_id) {
  self.postMessage({
    type: 'patch',
    patch: patch,
    buffers: buffers
  })
}

async function startApplication() {
  console.log("Loading pyodide!");
  self.postMessage({type: 'status', msg: 'Loading pyodide'})
  self.pyodide = await loadPyodide();
  self.pyodide.globals.set("sendPatch", sendPatch);
  console.log("Loaded!");
  await self.pyodide.loadPackage("micropip");
  const env_spec = ['https://cdn.holoviz.org/panel/wheels/bokeh-3.6.3-py3-none-any.whl', 'https://cdn.holoviz.org/panel/1.6.1/dist/wheels/panel-1.6.1-py3-none-any.whl', 'pyodide-http==0.2.1', 'holoviews', 'hvplot', 'numpy', 'pandas', 'scipy']
  for (const pkg of env_spec) {
    let pkg_name;
    if (pkg.endsWith('.whl')) {
      pkg_name = pkg.split('/').slice(-1)[0].split('-')[0]
    } else {
      pkg_name = pkg
    }
    self.postMessage({type: 'status', msg: `Installing ${pkg_name}`})
    try {
      await self.pyodide.runPythonAsync(`
        import micropip
        await micropip.install('${pkg}');
      `);
    } catch(e) {
      console.log(e)
      self.postMessage({
	type: 'status',
	msg: `Error while installing ${pkg_name}`
      });
    }
  }
  console.log("Packages loaded!");
  self.postMessage({type: 'status', msg: 'Executing code'})
  const code = `
  \nimport asyncio\n\nfrom panel.io.pyodide import init_doc, write_doc\n\ninit_doc()\n\nimport panel as pn\nimport hvplot.pandas\nimport pandas as pd\nimport numpy as np\nimport holoviews as hv\nfrom scipy import stats\n\ndf = pd.read_csv("customer_churn.csv")\n\ndef process_churn_data(df_path, dropna=True, dropna_threshold=0.01, col_to_drop=None, col_to_convert=None, convert_mapping={0: 'No', 1: 'Yes'}):\n    """\n    Cleans and summarizes a customer churn DataFrame. The data file needs to be mostly cleaned, with minor missing values.\n\n    Parameters:\n    - df_path: the path of your local data file, need to be a cleaned data file of csv, tsv, or xls.\n    - dropna (bool): Whether to remove rows with NaN values below the threshold (default True).\n    - dropna_threshold (float): Percentage threshold for dropping rows with NaN values (default 0.01).\n    - col_to_drop (list): Columns to drop from the DataFrame if they are irrelevant (optional).\n    - col_to_convert (str): Column to apply the convert_mapping conversion (optional).\n    - convert_mapping (dict): Mapping to convert integer values (default {0: 'No', 1: 'Yes'}).\n\n    Returns:\n    - tuple: Cleaned DataFrame, numeric columns and categorical columns as lists, data summary table\n    """\n\n    # Step 1: Load the data based on file extension\n    if df_path.endswith('.csv'):\n        df = pd.read_csv(df_path)\n    elif df_path.endswith('.tsv'):\n        df = pd.read_csv(df_path, sep='\\t')\n    elif df_path.endswith('.xls') or df_path.endswith('.xlsx'):\n        df = pd.read_excel(df_path)\n    else:\n        raise ValueError("Unsupported file format. Use .csv, .tsv, .xls, or .xlsx.")\n\n    if col_to_drop:\n        print(f"\\n1. Dropping specified columns: {col_to_drop}")\n        df = df.drop(columns=col_to_drop)\n        print(f"Remaining columns: {df.columns.tolist()}")\n\n    print("\\n2. Checking and handling NaN values...")\n    rows_with_nulls = df[df.isnull().any(axis=1)]\n    num_rows_with_nulls = len(rows_with_nulls)\n    print(f"Number of rows with NaN values: {num_rows_with_nulls}")\n\n    if dropna and num_rows_with_nulls < dropna_threshold * len(df):\n        df = df.dropna()\n        print(f"Dropped {num_rows_with_nulls} rows with NaN values.")\n    else:\n        print(f"Retained rows with NaN values as they are more than the threshold of {dropna_threshold * 100}%.")\n\n    # Step 4: Convert column values if specified\n    if col_to_convert:\n        print(f"\\n3. Converting column '{col_to_convert}' values using mapping {convert_mapping}...")\n        if col_to_convert in df.columns:\n            df[col_to_convert] = df[col_to_convert].map(convert_mapping)\n            print(f"Unique values in column '{col_to_convert}': {df[col_to_convert].unique()}")\n        else:\n            print(f"Column '{col_to_convert}' not found in the DataFrame.")\n\n    # Step 5: Summarize column types, missing values, and unique entries\n    numeric_cols = list(df.select_dtypes(include=[np.number]).columns)\n    categorical_cols = list(df.select_dtypes(exclude=[np.number]).columns)\n\n    # Removing col_to_convert from \`categorical_cols\` if it exists\n    if col_to_convert and col_to_convert in categorical_cols:\n        categorical_cols.remove(col_to_convert)\n\n    data_summary = {\n        col: {\n            'type': str(df[col].dtype),\n            'unique_values': len(df[col].unique())\n        } for col in df.columns\n    }\n\n    for col in numeric_cols:\n        data_summary[col].update({\n            'mean': df[col].mean(),\n            'median': df[col].median(),\n            'std': df[col].std(),\n            'min': df[col].min(),\n            'max': df[col].max(),\n            'range': df[col].max() - df[col].min()\n        })\n\n    summary_df = pd.DataFrame(data_summary).T\n\n    return df, numeric_cols, categorical_cols, data_summary\n    \n# plug in our data path to function above, unpack processed df, numeric_cols and categorical_cols, and add a ";" at end) to prevent displaying returned stuff\ndf, numeric_cols, categorical_cols, data_summary = process_churn_data('sampled_churn_data.csv', col_to_convert='Churn', col_to_drop=['CustomerID']);\n\n\ndef create_control_panel(var=True, group=False, range_slider_col=None, filter_col=None,\n                         var_default="Variable", group_default="Group By", range_name="Range Filter", filter_name="Filter By"):\n    """\n    Function to create control panel elements with optional variable selector, grouping selector,\n    range slider components, and a filter selector for categorical columns.\n\n    Parameters:\n    - var (bool): Whether to create a variable selector. Default is True.\n    - group (bool): Whether to create a grouping selector. Default is False.\n    - range_slider_col: One numerical column of choice to create a range slider. Default is None.\n    - filter_col (str): Column name to create a filter for specific values (e.g., 'Churn'). Default is None.\n    - var_default (str): Default name for the variable selector. Default is "Variable".\n    - group_default (str): Default name for the grouping selector. Default is "Group By".\n    - range_name (str): Name for the range slider. Default is "Range Filter".\n    - filter_name (str): Name for the filter selector. Default is "Filter By".\n\n    Returns:\n    - select_var: The variable selector widget.\n    - select_group: The grouping selector widget.\n    - slider: The range slider widget (if created).\n    - filter_select: The filter selector widget (if created).\n    - controls (pn.Column): A Panel Column layout of the created widgets.\n    """\n    widgets = []\n\n    # Create variable selector if 'var' is True\n    if var:\n        select_var = pn.widgets.Select(\n            options=numeric_cols,  # Options are the numeric columns\n            name=f"{var_default}: Choose the variable to analyze",  # Auto-generate name\n            value=numeric_cols[0],  # Default to the first value in numeric_cols\n            description=f"Choose the {var_default} to analyze"\n        )\n        widgets.append(select_var)\n\n    # Create grouping selector if 'group' is True\n    if group:\n        select_group = pn.widgets.Select(\n            options=categorical_cols,  # Filter categorical columns\n            name=group_default,  # Default or user-specified name\n            value=categorical_cols[0],  # Default to the first value in categorical_cols\n            description=f"Choose the column to {group_default.lower()} by"\n        )\n        widgets.append(select_group)\n\n    # Create range slider if 'range_slider_cols' is provided\n    if range_slider_col:\n        slider = pn.widgets.RangeSlider(\n            name=f"{range_name}: {range_slider_col}",  # Auto-generate name with the column\n            start=df[range_slider_col].min(),\n            end=df[range_slider_col].max(),\n            value=(df[range_slider_col].min(), df[range_slider_col].max()),  # Default range matches column range\n            step=1,\n            format='0[.]0'\n        )\n        widgets.append(slider)\n\n    # Create filter selector for a specific column if 'filter_col' is provided\n    if filter_col:\n        filter_select = pn.widgets.Select(\n            options=['Yes', 'No'],  # Unique values in the specified column\n            name=f"{filter_name}: {filter_col}",  # Auto-generate name with the column\n            value='Yes',  # Set default to the first value in the column\n            description=f"{filter_name} column: {filter_col}"\n        )\n        widgets.append(filter_select)\n\n    # Create layout with all widgets\n    controls = pn.Column(\n        '## Dashboard Controls',\n        *widgets,  # Unpack widgets in the column\n        sizing_mode='stretch_width'\n    )\n\n    return range_slider_col, filter_col, select_var, select_group, slider, filter_select, controls  # Add filter_select to the returned values\n# Create a control panel with all options enabled\nrange_slider_col, filter_col, select_var, select_group, slider, filter_select, controls = create_control_panel(\n    var=True,\n    group=True,\n    filter_col='Churn',\n    range_slider_col='Total Spend', # we are particularly interested in how this variable affecting others\n    var_default="Analysis Variable",\n    group_default="Grouping Category",\n    range_name="Filter by Range"\n)\n\n\n@pn.depends(select_group, slider)\ndef barchart(select_group, slider):\n    \n    filtered_df = df[\n        (df[range_slider_col] >= slider[0]) &\n        (df[range_slider_col] <= slider[1])\n    ]\n\n    # create barchart\n    bar_chart = filtered_df.groupby([select_group, filter_col]).size().unstack().hvplot.bar(\n        x=select_group,\n        y=['Yes', 'No'],\n        stacked=True,\n        title=f'{filter_col} by {select_group}',\n        xlabel='select_group',\n        ylabel='Count',\n        legend='top'\n    )\n\n    return bar_chart\n\nbarchart_layout = pn.Column(\n    pn.pane.Markdown("### Interactive Bar Chart (Demo Only, Do Not Click)"), \n    select_group,\n    slider,\n    pn.panel(barchart),  \n    sizing_mode="stretch_both"\n)\n\n\n# @pn.depends tells Panel which widgets should trigger updates\n@pn.depends(select_var, slider, filter_select)\ndef histogram_plot(select_var, slider, filter_select):\n    """\n    Creates an interactive histogram for selected variable with density curves.\n\n    Args:\n        select_var (str): The variable to plot\n        select_group (str): The grouping variable\n\n    Returns:\n        hvplot: Interactive histogram plot\n    """\n\n    # filter data based on parameters\n    selected_df = df[df[filter_col] == filter_select]\n\n    filtered_df = selected_df[\n        (selected_df[range_slider_col] >= slider[0]) &\n        (selected_df[range_slider_col] <= slider[1])\n    ]\n\n    # add density curve\n    x_min = filtered_df[select_var].min()\n    x_max = filtered_df[select_var].max()\n    sw = np.linspace(x_min, x_max, 1000)\n    fit = stats.norm.pdf(sw, np.mean(filtered_df[select_var]), np.std(filtered_df[select_var]))\n    bin_width = (x_max - x_min) / 20\n    fit_scaled = fit * len(filtered_df) * bin_width\n\n    density_curve = hv.Curve((sw, fit_scaled)).opts(\n    line_width=2,\n    color='red'\n)\n\n    # Create the plot with some customization\n    histogram = filtered_df.hvplot.hist(\n        y=select_var,\n        bins=20,\n        height=300,\n        alpha=0.5,\n        title=f'Histogram for {select_var}',\n        xlabel=select_var,\n        ylabel='Count',\n        **{'responsive': True,\n           'legend_position': 'right'}\n    )\n\n    return density_curve * histogram\n\nhist_layout = pn.Column(\n    pn.pane.Markdown("### Interactive Historgram (Demo Only, Do Not Click)"), \n    select_var, select_group, slider, filter_select,\n    pn.panel(histogram_plot),  \n    sizing_mode="stretch_both"\n)\n\n\n@pn.depends(select_var, select_group, slider, filter_select)\ndef box_plot(select_var, select_group, slider, filter_select):\n    """Creates a box plot for selected variables and range, if provided. It also includes hover tooltips for more interactivity.\n\n    Args:\n        select_var (str): Variable to plot on y-axis\n        select_group (str): Grouping variable for x-axis\n\n    Returns:\n        hvplot: Interactive box plot\n    """\n    # First, let's filter our data\n\n    # filter data based on parameters\n    selected_df = df[df[filter_col] == filter_select]\n\n    filtered_df = selected_df[\n        (selected_df[range_slider_col] >= slider[0]) &\n        (selected_df[range_slider_col] <= slider[1])\n    ].copy() # Create a copy to avoid SettingWithCopyWarning\n\n\n    # get statistics for hover tooltips\n    stats = {\n        group: {\n            'median': filtered_df[filtered_df[select_group]==group][select_var].median(),\n            'mean': filtered_df[filtered_df[select_group]==group][select_var].mean(),\n            'std': filtered_df[filtered_df[select_group]==group][select_var].std()\n        } for group in filtered_df[select_group].unique()\n    }\n\n    # Create the box plot\n    plot = filtered_df.hvplot.box(\n        y=select_var,\n        by=select_group,\n        height=300,\n        whisker_color='black',\n        title=f'Boxplot for {select_var} by {select_group}',\n\n        # Customize appearance\n        box_alpha=0.7,\n        outlier_alpha=0.7,\n        width=400,\n        legend='top',\n\n        # Add statistical hover texts\n        tools=['hover'],\n        tooltips=[\n            ('Group', '@{' + select_group + '}'),\n            ('Value', '@{' + select_var + '}{0.00}'),\n            ('Count', '@count'),\n            ('Median', '@median{0.00}')\n        ]\n    )\n\n    return plot\n\nboxplot_layout = pn.Column(\n    pn.pane.Markdown("### Interactive Boxplot (Demo Only, Do Not Click)"), \n    select_var, select_group, slider, filter_select,\n    pn.panel(box_plot),  \n    sizing_mode="stretch_both"\n)\n\n\n@pn.depends(select_var, slider, filter_select, select_group)\ndef create_scatter(x_var, slider, filter_select, group_var):\n    """\n    Creates an interactive scatter plot with points grouped by a specified column.\n\n    Args:\n        x_var (str): The variable to use on the x-axis.\n        slider (RangeSlider): RangeSlider object to filter data by a numeric range.\n        filter_select (str): Column value used to filter rows (e.g., 'Yes' for column 'Churn').\n        group_var (str): Column name to group data points by (e.g., 'Gender').\n\n    Returns:\n        hvPlot: An interactive scatter plot, grouped by the specified column with colors, with hover tools and interactivity.\n    """\n\n    # Filter data based on parameters\n    selected_df = df[df[filter_col] == filter_select]\n\n    filtered_df = selected_df[\n        (selected_df[range_slider_col] >= slider[0]) &\n        (selected_df[range_slider_col] <= slider[1])\n    ]\n\n    # Determine the y-variable\n    y_var = range_slider_col if x_var != range_slider_col else 'hp'\n\n    # Identify unique groups\n    groups = filtered_df[group_var].unique()\n\n    combined = None\n\n    for i, g in enumerate(groups):\n        group_data = filtered_df[filtered_df[group_var] == g]\n\n        # Introduce jitter to reduce overlapping points\n        group_data[x_var] += np.random.uniform(-0.5, 0.5, size=len(group_data))\n        group_data[y_var] += np.random.uniform(-0.5, 0.5, size=len(group_data))\n\n        # Create scatter plot for this group with transparency\n        scatter = group_data.hvplot.scatter(\n            x=x_var,\n            y=y_var,\n            alpha=0.6,\n            label=str(g),\n            size=5\n        )\n\n        # Combine with previous groups\n        if combined is None:\n            combined = scatter\n        else:\n            combined = combined * scatter\n\n    # Add options to the combined plot\n    plot = combined.opts(\n        width=600,\n        height=400,\n        title=f'Relationship between {x_var} and {y_var}\\n(grouped by {group_var})',\n        tools=['hover', 'box_zoom', 'reset'],\n        show_grid=True,\n        toolbar='above'\n    )\n\n    return plot\n\nscatter_layout = pn.Column(\n    pn.pane.Markdown("### Interactive Scartterplot (Demo Only, Do Not Click)"), \n    select_var, select_group, slider, filter_select,\n    pn.panel(create_scatter),  \n    sizing_mode="stretch_both"\n)\n\n\ndef create_dashboard(widgets, plots):\n    # Extract widgets\n    select_var, select_group, slider, filter_select = widgets\n\n    # Create separate control layouts for each tab\n    # General Tab: Only select_group and slider\n    general_controls = pn.Column(\n        select_group,\n        slider,\n        sizing_mode="stretch_width"\n    )\n\n    # Distributions and Correlations Tabs: All widgets\n    other_controls = pn.Column(\n        *widgets,  # Include all widgets\n        sizing_mode="stretch_width"\n    )\n\n    # Create tabs\n    tabs = pn.Tabs(\n        ('Categorical', pn.Column(\n            general_controls,  # Only select_group and slider\n            pn.Row(plots['barchart'], sizing_mode='stretch_both'),\n            sizing_mode='stretch_both'\n        )),\n        ('Numerial', pn.Column(\n            other_controls,  # All widgets\n            pn.Row(plots['boxplot'], plots['histogram'], sizing_mode='stretch_both'),\n            sizing_mode='stretch_both'\n        )),\n        ('Correlations', pn.Row(\n            other_controls,  # All widgets\n            plots['scatter'],\n            sizing_mode='stretch_both'\n        )),\n        ('Statistics', pn.Column(\n            # No widgets for stats tab\n            plots['stats'],\n            sizing_mode='stretch_both'\n        )),\n        sizing_mode='stretch_both'\n    )\n\n    main_layout = pn.Column(tabs, sizing_mode='stretch_both').servable()\n\n    template = pn.template.VanillaTemplate(\n        title="Interactive EDA Dashboard",\n        sidebar=[],\n        main=[main_layout],\n    )\n\n    return template\n\n# Initialize and display the dashboard\ndashboard = create_dashboard(\n    widgets=[select_var, select_group, slider, filter_select],\n    plots={\n        'barchart': barchart,\n        'histogram': histogram_plot,\n        'boxplot': box_plot,\n        'scatter': create_scatter,\n        'stats': pd.DataFrame(data_summary)\n    }\n)\n\n\n\nawait write_doc()
  `

  try {
    const [docs_json, render_items, root_ids] = await self.pyodide.runPythonAsync(code)
    self.postMessage({
      type: 'render',
      docs_json: docs_json,
      render_items: render_items,
      root_ids: root_ids
    })
  } catch(e) {
    const traceback = `${e}`
    const tblines = traceback.split('\n')
    self.postMessage({
      type: 'status',
      msg: tblines[tblines.length-2]
    });
    throw e
  }
}

self.onmessage = async (event) => {
  const msg = event.data
  if (msg.type === 'rendered') {
    self.pyodide.runPythonAsync(`
    from panel.io.state import state
    from panel.io.pyodide import _link_docs_worker

    _link_docs_worker(state.curdoc, sendPatch, setter='js')
    `)
  } else if (msg.type === 'patch') {
    self.pyodide.globals.set('patch', msg.patch)
    self.pyodide.runPythonAsync(`
    from panel.io.pyodide import _convert_json_patch
    state.curdoc.apply_json_patch(_convert_json_patch(patch), setter='js')
    `)
    self.postMessage({type: 'idle'})
  } else if (msg.type === 'location') {
    self.pyodide.globals.set('location', msg.location)
    self.pyodide.runPythonAsync(`
    import json
    from panel.io.state import state
    from panel.util import edit_readonly
    if state.location:
        loc_data = json.loads(location)
        with edit_readonly(state.location):
            state.location.param.update({
                k: v for k, v in loc_data.items() if k in state.location.param
            })
    `)
  }
}

startApplication()